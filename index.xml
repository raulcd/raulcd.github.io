<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Raúl Cumplido&#39;s Blog</title>
    <link>https://raul.dev/</link>
    <description>Recent content on Raúl Cumplido&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Feb 2025 11:11:19 +0000</lastBuildDate><atom:link href="https://raul.dev/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Keeping symbols to yourself</title>
      <link>https://raul.dev/post/symbol_table_and_dynamic_symbol_table/</link>
      <pubDate>Wed, 05 Feb 2025 11:11:19 +0000</pubDate>
      
      <guid>https://raul.dev/post/symbol_table_and_dynamic_symbol_table/</guid>
      <description>I usually forget things so I created this blog post so I can come back to it in the future with what I learnt while working on it.
The One Definition Rule on C++ tells us that we can&amp;rsquo;t have more than one definition in the entire program for classes and structs. I hit some issues with it while doing some work on Arrow in order to load newer Kernels into older versions of Arrow.</description>
    </item>
    
    <item>
      <title>Split Arrow CPP libraries on conda</title>
      <link>https://raul.dev/post/split_libarrow_on_conda/</link>
      <pubDate>Tue, 28 Nov 2023 11:11:19 +0000</pubDate>
      
      <guid>https://raul.dev/post/split_libarrow_on_conda/</guid>
      <description>It has been a really long time since I have written anything but during the last year I have been involved in the development and releases of Apache Arrow and I have been contributing to the project and the overall ecosystem.
One of the things I have worked during the last months has been to divide the Apache Arrow C++ conda package into subpackages in order to provide a more modular installation.</description>
    </item>
    
    <item>
      <title>Data structures: Python lists</title>
      <link>https://raul.dev/post/python_list_data_structure/</link>
      <pubDate>Sat, 02 Mar 2019 12:15:19 +0000</pubDate>
      
      <guid>https://raul.dev/post/python_list_data_structure/</guid>
      <description>Lately I&amp;rsquo;ve been reviewing some algorithms and some data structures. A python list is basically a dynamic array that allows to read and append at constant time.
An array has constant read time O(1) but linear O(n) write time as everytime you need to add a new element a new array needs to be allocated in memory and copied to the new location.
Python list has a constant insertion time. How is Python doing that?</description>
    </item>
    
    <item>
      <title>Blog Reborn</title>
      <link>https://raul.dev/post/blog_reborn/</link>
      <pubDate>Thu, 28 Feb 2019 20:40:19 +0000</pubDate>
      
      <guid>https://raul.dev/post/blog_reborn/</guid>
      <description>It has been a really long time since I have not written anything. I started my own blog 4 years ago and I have decided to start writing again.
There are several reasons behind it.
I am always trying to learn but lately I am taking some efforts to do it more consistently. I want to have a place where I can put my notes. Having them publicly available might help someone.</description>
    </item>
    
    <item>
      <title>How Python caches compiled bytecode.</title>
      <link>https://raul.dev/post/python_optimized_files/</link>
      <pubDate>Tue, 17 Mar 2015 11:30:00 +0000</pubDate>
      
      <guid>https://raul.dev/post/python_optimized_files/</guid>
      <description>While reading an email at the Python developers mailing list about PEP-488 (which is not yet approved and is under discussion) I wondered how bytecode files works in Python.
The purpose of this post is to take some notes for myself and share what I find.
PEP-3147 While I was reading the proposed PEP-488 (which will be explained later) there was several references to PEP-3147.
Before PEP-3147 was implemented, files were saved with the format &#39;{filename}.</description>
    </item>
    
    <item>
      <title>Elasticsearch, Logstash and Kibana on Docker</title>
      <link>https://raul.dev/post/elastic_search_logstash_kibana/</link>
      <pubDate>Wed, 11 Feb 2015 18:30:00 +0000</pubDate>
      
      <guid>https://raul.dev/post/elastic_search_logstash_kibana/</guid>
      <description>While doing performance testing on a project I needed to process the access logs of our web servers to define the navigation profile of our current users.
So I though it would be a nice time to play with Elasticsearch, Logstash and Kibana as I&amp;rsquo;ve heard of the stack.
ELK Stack The first thing to notice when using it is how easy to use is. It took me a couple of hours since I decided to use it to have a prototype working on my local host.</description>
    </item>
    
    <item>
      <title>Create Blog using Pelican and deploy in github pages</title>
      <link>https://raul.dev/post/generate_pelican_blog/</link>
      <pubDate>Mon, 07 Jul 2014 18:30:00 +0000</pubDate>
      
      <guid>https://raul.dev/post/generate_pelican_blog/</guid>
      <description>This website has been created using pelican. Pelican is static site generator written in Python.
Basically the needs for the project were:
Easy deployment and mantainance Write articles using Markdown Code syntax highlighting After a quick research in order to select the framework to use in order to keep things simple, Pelican had all the features needed.
Generation of website Pelican is really easy to start with. You just need to create your project and install pelican:</description>
    </item>
    
  </channel>
</rss>
